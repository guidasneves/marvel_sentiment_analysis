{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9928e43-0156-4890-a2fd-42ee5e0133c4",
   "metadata": {},
   "source": [
    "# RNN Model Train Step (Etapa do Treinamento do Modelo LSTM)\n",
    "**[EN-US]**\n",
    "\n",
    "Training and evaluation stage of the LSTM model, and then we save the model and its respective trained weights.\n",
    "\n",
    "In this step we perform:\n",
    "* Model definition;\n",
    "* Model training;\n",
    "* Model evaluation;\n",
    "* Saving the model and trained weights.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "Etapa do treinamento e avaliação do modelo LSTM, para depois, salvarmos o modelo e seus respectivos pesos treinados.\n",
    "\n",
    "Nesta etapa realizamos:\n",
    "* Definição do modelo;\n",
    "* Treinamento do modelo;\n",
    "* Avaliação do modelo;\n",
    "* Salvamento do modelo e dos pesos treinados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e087c-b700-4fd8-96dc-ab3cb28c8e9b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Packages](#1)\n",
    "* [Loading the Data](#2)\n",
    "* [Hyperparameters Tuning](#3)\n",
    "* [RNN Model](#4)\n",
    "    * [Embedding](#4.1)\n",
    "    * [LSTM Layer](#4.2)\n",
    "* [Bidirectional LSTM Model Train](#5)\n",
    "    * [Model Architecture](#5.1)\n",
    "* [Inference](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8359568-c47e-489e-95b3-fe92b4fbf658",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## Packages (Pacotes)\n",
    "**[EN-US]**\n",
    "\n",
    "Packages used in the system.\n",
    "* [pandas](https://pandas.pydata.org/): is the main package for data manipulation;\n",
    "* [numpy](www.numpy.org): is the main package for scientific computing;\n",
    "* [pickle](https://docs.python.org/3/library/pickle.html): implements binary protocols for serializing and de-serializing a Python object structure;\n",
    "* [tensorflow](https://www.tensorflow.org/): framework that makes it easy to create ML models that can run in any environment;\n",
    "* [skopt](https://scikit-optimize.github.io/stable/): is a simple and efficient library to minimize (very) expensive and noisy functions;\n",
    "* [matplotlib](http://matplotlib.org): is a library to plot graphs;\n",
    "* [os](https://docs.python.org/3/library/os.html): built-in module, provides a portable way of using operating system dependent functionality;\n",
    "* [sys](https://docs.python.org/3/library/sys.html): provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter;\n",
    "* [src](../src/): package with all the codes for all utility functions created for this system. Located inside the `../src/` directory.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "Pacotes utilizados no sistema.\n",
    "* [pandas](https://pandas.pydata.org/): é o principal pacote para manipulação de dados;\n",
    "* [numpy](www.numpy.org): é o principal pacote para computação científica;\n",
    "* [pickle](https://docs.python.org/3/library/pickle.html): implementa protocolos binários para serializar e desserializar uma estrutura de objeto Python;\n",
    "* [tensorflow](https://www.tensorflow.org/): framework que facilita a criação de modelos de machine learning que podem ser executados em qualquer ambiente;\n",
    "* [skopt](https://scikit-optimize.github.io/stable/): é uma biblioteca simples e eficiente para minimizar funções (muito) caras computacionalmente e ruidosas;\n",
    "* [matplotlib](http://matplotlib.org): é uma biblioteca para plotar gráficos;\n",
    "* [os](https://docs.python.org/3/library/os.html): módulo integrado, fornece uma maneira portátil de usar funcionalidades dependentes do sistema operacional;\n",
    "* [sys](https://docs.python.org/3/library/sys.html): fornece acesso a algumas variáveis usadas ou mantidas pelo interpretador e a funções que interagem fortemente com o interpretador;\n",
    "* [src](../src/): pacote com todos os códigos de todas as funções utilitárias criadas para esse sistema. Localizado dentro do diretório `../src/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "375d1727-909a-4086-ba17-f377c05c39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from skopt import gp_minimize\n",
    "\n",
    "import os\n",
    "import sys\n",
    "PROJECT_ROOT = os.path.abspath( # Getting Obtaining the absolute normalized version of the project root path (Obtendo a versão absoluta normalizada do path raíz do projeto)\n",
    "    os.path.join( # Concatenating the paths (Concatenando os paths)\n",
    "        os.getcwd(), # # Getting the path of the notebooks directory (Obtendo o path do diretório dos notebooks)\n",
    "        os.pardir # Gettin the constant string used by the OS to refer to the parent directory (Obtendo a string constante usada pelo OS para fazer referência ao diretório pai)\n",
    "    )\n",
    ")\n",
    "# Adding path to the list of strings that specify the search path for modules\n",
    "# Adicionando o path à lista de strings que especifica o path de pesquisa para os módulos\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "from src.rnn_model_train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3705eb-ec9b-4dcb-8e7a-178a41c04871",
   "metadata": {},
   "source": [
    "**[EN-US]**\n",
    "\n",
    "> **Note**: the codes for the utility functions used in this system are in the `rnn_model_train.py` script within the `../src/` directory.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "> **Nota**: os códigos para as funções utilitárias utilizadas nesse sistema estão no script `rnn_model_train.py` dentro do diretório `../src/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02bd306-a269-46e3-8f5d-e8b4a62bc355",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## Loading the Data (Carregando os Dados)\n",
    "**[EN-US]**\n",
    "\n",
    "We will read each subset from disk, define the global variables for creating the dataset and model, and we will create the `tensorflow.data.Dataset` for each subset.\n",
    "\n",
    "Reading each of the subsets from the `../data/preprocessed/` directory and plotting their dimensions.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "Vamos ler cada subset do disco, definir as variáveis globais para a criação do dataset e do modelo, e vamos criar o `tensorflow.data.Dataset` de cada subset.\n",
    "\n",
    "Lendo cada um dos subsets do diretório `../data/preprocessed/` e plotando as suas dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ea5f4e-43f0-45e2-a4fd-cbc05d7f08d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (9682, 167)\n",
      "Validation set shape: (3227, 167)\n",
      "Test set shape: (3228, 167)\n"
     ]
    }
   ],
   "source": [
    "# Subset names\n",
    "# Nomes dos subsets\n",
    "files = ['train', 'validation', 'test']\n",
    "datasets = []\n",
    "# Looping through each name\n",
    "# Percorrendo cada nome\n",
    "for file in files:\n",
    "    # Reading each subset and adding it to the list for later extraction\n",
    "    # Lendo cada subset e adicionando na lista para extração posteriormente\n",
    "    with open(f'../data/preprocessed/{file}_tokens.npy', 'rb') as f:\n",
    "        datasets.append(np.load(f))\n",
    "\n",
    "# Extracting each subset from the `datasets` list\n",
    "# Extraindo cada subset da lista `datasets`\n",
    "train_corpus, val_corpus, test_corpus = datasets\n",
    "print(f'Train set shape: {train_corpus.shape}\\nValidation set shape: {val_corpus.shape}\\nTest set shape: {test_corpus.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a9b0f0-f877-4138-81bb-8dcc0ed65e58",
   "metadata": {},
   "source": [
    "**[EN-US]**\n",
    "\n",
    "Setting global variables to create `tensorflow.data.Dataset` and global variables to create the model.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "Definindo as variáveis globais para criar o `tensorflow.data.Dataset` e as variáveis globais para a criação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e88c26-e353-4a91-a2f2-fa1a41659f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1000\n",
      "Max length: 166\n"
     ]
    }
   ],
   "source": [
    "# Dataset global variables\n",
    "# Variáveis globais do dataset\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "# Model global variables\n",
    "# Variáveis globais do modelo\n",
    "tokenizer = pickle.load(open('../models/vectorizer.pkl', 'rb'))\n",
    "MAX_LEN = tokenizer['config']['output_sequence_length']\n",
    "EMBEDDING_DIM = 16\n",
    "DROPOUT_RATE = [.5, .5]\n",
    "LR = 5e-3\n",
    "VOCAB_SIZE = len(tokenizer['vocabulary']) # Carregando o vocabulário do tokenizer treinado # Loading vocabulary from trained tokenizer\n",
    "print(f'Vocabulary size: {VOCAB_SIZE}\\nMax length: {MAX_LEN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328c5a6-9fdf-4596-b8d0-e601b97ca605",
   "metadata": {},
   "source": [
    "Creating `tensorflow.data.Dataset` for each subset and plotting the training set dimension (Criando o `tensorflow.data.Dataset` para cada subset e plotando a dimensão do training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86fba599-081a-4c37-835a-fd7a74e5286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train batch: (32, 166)\n"
     ]
    }
   ],
   "source": [
    "train_set = create_batch_dataset(train_corpus, BATCH_SIZE, BUFFER_SIZE, shuffle=True)\n",
    "val_set = create_batch_dataset(val_corpus, BATCH_SIZE, BUFFER_SIZE, shuffle=True)\n",
    "test_set = create_batch_dataset(test_corpus, BATCH_SIZE, BUFFER_SIZE, shuffle=True)\n",
    "\n",
    "train_batch = next(train_set.as_numpy_iterator())\n",
    "print(f\"Shape of the train batch: {train_batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1f0a3-af46-4ca5-b27f-1cad6491625e",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## Hyperparameters Tuning (Otimização dos Hiperparâmetros)\n",
    "**[EN-US]**\n",
    "\n",
    "The method used to search for the best hyperparameters for the model was `Bayesian optimization`.\n",
    "\n",
    "Computing Bayesian Optimization.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "O método utilizado para a busca dos melhores hiperparâmetros para o modelo foi a otimização bayesiana (`bayesian optimization`).\n",
    "\n",
    "Calculando a otimização bayesiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dca1da44-5bd9-4494-8c99-b2c75140557d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining the range for testing learning rate\n",
    "# Definindo a faixa para teste da learning rate\n",
    "space = [\n",
    "    (1e-4, 1e-1, 'log-uniform') # learning rate\n",
    "]\n",
    "\n",
    "# Performing Bayesian optimization\n",
    "# Performando a bayesian optimization\n",
    "#opt = gp_minimize(hyperparams_tune, space, random_state=42, verbose=0, n_calls=5, n_random_starts=2)\n",
    "# Output with the best combinations of hyperparameters\n",
    "# Output com as melhores combinações dos hiperparâmetros\n",
    "#print(f'Learning rate: {opt.x[0]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc150b-e9c4-490d-837d-47605d5b4f0e",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## RNN Model (Modelo RNN)\n",
    "**[EN-US]**\n",
    "\n",
    "We can try using a standard neural network for this task, or maybe even logistic regression, or Naive Bayes, but these models don't perform well for NLP tasks, and the main problems are:\n",
    "* Inputs and outputs may have different lengths in different examples. Generally, we fill all inputs to a maximum length, but this still doesn't seem like a good representation.\n",
    "* Does not share features learned between different positions (time steps $t$) of texts. We like effects similar to CNNs for sequential data, where we want things learned for one part of the image to quickly generalize to other parts of the image.\n",
    "    * If the standard neural network, with the value \"Iron Man\" for input unit 1 (time step 1), analyzes that this is part of a person's name, then, wouldn't it be good if we discovered that \"Iron Man\" appearing in another input unit (time step $t \\neq 1$), this also means that this could be a person's name.\n",
    "* The FC (Dense) layer will have a huge number of parameters. As with ConvNets, using a good representation will also allow us to reduce the number of parameters in our model.\n",
    "\n",
    "For these reasons, we use a sequential network, which will allow us to predict sentiments in complex sentences, which we would not be able to classify correctly using simpler methods, because they miss important information. At each time step $t$, the RNN passes its activation to the next time step for use. To start everything off, we will also have an activation invented at time 0, $a^{<0>}$, which is a vector of 0s, but we can also initialize it randomly.\n",
    "* We denote the time step $t$ as $<t>$, that is, $x^{<1>}$, is the token of time step 1 of the input $x$.\n",
    "\n",
    "Each of the units (words) represents the calculations made in each time step. The calculations performed in the last step contain information about all the words in that sentence. The RNN examines the data from left to right, and the parameters used for each time step are shared. The parameters that govern the connection of $x^{<1>}$ with the hidden layer, will be a set $W_{ax}$ of parameters, and are the same $W_{ax}$ parameters that it uses for each time step. Activations, horizontal connections will be governed by $W_{aa}$, similar to $W_{ax}$. Also similar to $W_{ax}$, $W_{ya}$ governs the output predictions.\n",
    "\n",
    "The magic of RNNs is that the information for each word in the sentence is multiplied by the same weights, $W_x$. The information propagated from start to finish is multiplied by $W_h$. The first block is repeated for each word in the sentence, so the only parameters that can be learned are $W_x$, $W_h$ and $W$, the weights used to make the final prediction. This is why they are called recurrent neural networks, they calculate values that are repeatedly transmitted to themselves until a prediction is made. The main advantage of RNNs is that they propagate information in sentences and their calculations share most of the parameters.\n",
    "\n",
    "The hidden states in each time step $t$ are calculated with an activation function $g$, with the arguments equal to the product between a matrix of parameters $W_h$ and the previous hidden states $h^{<t - 1>}$, this is concatenated with the input variable $x^{<t>}$, plus the bias $b_h$:\n",
    "$$h^{<t>} = g(W_h [h^{<t - 1>}, x^{<t>}] + b_h)$$\n",
    "Complete equation, where $x^{<t>}$ and $h^{<t - 1>}$ are multiplied by different parameters and the resulting vectors are added element by element:\n",
    "$$h^{<t>} = g(W_{hh} h^{<t - 1>} + W_{hx} x^{<t>} + b_h)$$\n",
    "* $W_h[h^{<t - 1>}, x^{<t>}]$ is the same as multiplying $W_{hh}$ by $h^{<t - 1>}$ and $W_{hx}$ by $x^{<t>}$. So we can concatenate.\n",
    "* $W_h$ denotes the horizontal concatenation of the weight matrices $W_{hh}$ and $W_{hx}$.\n",
    "    * The join over the vertical limit is called `horizontal concatenation` or `horizontal stack`, that is, $W_h = | W_{hh} | W_{hx} |$.\n",
    "\n",
    "After calculating the hidden state in time step $t$, it is possible to obtain the prediction $\\hat{y}^{<t>}$ using the activation function $g$, with arguments equal to the product between the hidden state and some parameters $W$, plus the bias term $b_y$:\n",
    "$$\\hat{y}^{<t>} = g(W_{yh} h^{<t>} + b_y)$$\n",
    "\n",
    "These 2 equations together represent all the math behind a simple RNN. The first cell of the RNN receives as input the previous hidden state $h^{<t_0>}$ and the current variable $x^{<t_1>}$, which can be the first word in a sentence. To obtain the current hidden state $h^{<t_1>}$, we first need to obtain the products of $x^{<t_1>}$ and $h^{<t_0>}$ with the respective parameters and then add the vectors element-wise. We then pass the resulting vector into an activation function.\n",
    "$$h^{<t>} = g(W_{hh} h^{<t - 1>} + W_{hx} x^{<t>} + b_h)$$\n",
    "With the resulting value, we can calculate $\\hat{y}^<t>$ by multiplying the current hidden state, with a set of parameters $W_{yh}$ and passing through another activation function.\n",
    "$$\\hat{y}^{<t>} = g(W_{yh} h^{<t>} + b_y)$$\n",
    "The hidden states $h^{<t>}$ are the variables that cause the RNNs to propagate information over time or, in other words, through different positions in the sentence. In each time step the recurrent units have 2 inputs.\n",
    "\n",
    "We can think of RNNs as versatile tools that can be tailored to the task. Therefore, according to the nature of the inputs and outputs, there are many different types of RNN architectures:\n",
    "\n",
    "* `One to One`: takes as input a set of low features or uncorrelated features $X$ and returns a single output $y$. Let's say we have a list of scores for our favorite team. As inputs, we can have an RNN that predicts our team's position on the leaderboard. However, this RNN is not much different from a conventional neural network. It only has additional hidden states $h^{<t_0>}$. Therefore, for this type of task, RNNs are not very useful.\n",
    "\n",
    "* `One to Many`: if we want a neural network that takes an arbitrary image and generates a caption describing the content of that image (caption generation task), we can create an RNN. One to Many, because our RNN takes a single image and generates multiple words to describe it.\n",
    "\n",
    "* `Many to One`: if we have a sentence, our RNN would take each word in the sentence as input in different steps, propagate the information from start to finish and generate a single output, the feeling, for example.\n",
    "\n",
    "* `Many to Many`: involve multiple inputs and multiple outputs. For example, in machine translation, we have a sentence in one language and we want to get its equivalent in another language, we use an `encoder` and a `decoder` to translate from one language to another. We can use a machine translation system that has RNNs for both the encoder and decoder, because they propagate information from beginning to end and this is what makes them capable of capturing the general meaning of sentences. The traditional `seq2seq` model was introduced by Google in 2014. Basically, it works by receiving a sequence of items, such as words, and its output is another sequence. The way this is done is by mapping variable-length sequences to a fixed-length memory, which in machine translation encodes the general meaning of the sentences. For example, we can take variable-length text and encode it into a fixed-dimension vector, like 300. This feature is what made this model a powerhouse for machine translation. Furthermore, inputs and outputs do not need to have corresponding lengths, which is a desirable feature when translating texts. In the seq2seq model, LSTMs and GRUs are typically used to avoid these problems. In a seq2seq model we have an encoder and a decoder:\n",
    "    * `Encoder`: receives tokens as input and returns their final hidden states $h_T$ as output.\n",
    "    * `Decoder`: receives the encoder output, the final hidden states, which are used by the decoder as initial hidden states to generate the translated sentence in the target language.\n",
    "\n",
    "Vanilla (simple) RNNs are limited in the sense that, for long sequences of words, information tends to disappear, that is, the problem of vanishing/exploding gradients. Therefore, more complex models were created to deal with long sequences and exponentially reduce this problem, these models are `GRU` and `LSTM`. Deep RNNs are useful because they allow us to capture dependencies that we otherwise could not have captured using shallow RNNs. Both architectures are derived from Vanilla (simple) RNN.\n",
    "* `Vanishing gradients`: When we calculate backprop, the gradients can become very small and as a result the model will not learn anything.\n",
    "* `Exploding gradients`: if the partial derivatives are greater than 1, the contribution to the gradient goes to infinity, which causes convergence problems during training.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "Podemos tentar usar uma rede neural padrão para essa tarefa, ou talvez até uma regressão logística, ou um Naive Bayes, mas esses modelos não obtém um bom desempenho para tarefas de NLP, e os problemas principais são:\n",
    "* Inputs e outputs podem ter comprimentos diferentes em exemplos diferentes. Geralmente, preenchemos todos os inputs até um comprimento máximo, mas isso ainda não parece uma boa representação.\n",
    "* Não compartilha features aprendidas entre diferentes posições (time steps $t$) de textos. Gostamos de efeitos semelhantes as CNNs para dados sequênciais, onde desejamos que as coisas aprendidas para uma parte da imagem, se generalizem rapidamente para outras partes da imagem.\n",
    "    * Caso a rede neural padrão, com o valor \"Iron Man\" para a input unit 1 (time step 1), analisa que isso faz parte do nome de uma pessoa, então, não seria bom se descobrissemos que aparecendo \"Iron Man\" em outra input unit (time step $t \\neq 1$), isso também significa que esse pode ser o nome de uma pessoa.\n",
    "* A FC (Dense) layer terá um número enorme de parâmetros. Assim como nas ConvNets, usar uma boa representação também permitirá reduzir o número de parâmetros do nosso modelo.\n",
    "\n",
    "Por esses motivos, utilizamos uma rede sequencial, que nos permitirá prever sentimentos em frases complexas, que não conseguiríamos classificar corretamente usando métodos mais simples, porque eles perdem informações importantes. Em cada time step $t$, a RNN passa sua ativação para o próximo time step para ser usada. Para começar tudo, também teremos uma ativação inventada no tempo 0, $a^{<0>}$, que é um vetor de 0s, mas também podemos inicializá-lo aleatoriamente.\n",
    "* Denotamos o time step $t$ como $<t>$, ou seja, $x^{<1>}$, é o token do time step 1 do input $x$.\n",
    "\n",
    "Cada uma das units (palavras) representa os cálculos feitos em cada time step. Os cálculos realizados no último step contêm informações de todas as palavras dessa frase. A RNN examina os dados da esquerda para a direita, e os parâmetros usados para cada time step são compartilhados. Os parâmetros que governam a conexão de $x^{<1>}$ com o hidden layer, serão um set $W_{ax}$ de parâmetros, e são os mesmo parâmetros $W_{ax}$ que ela usa para cada time step. As ativações, conexões horizontais serão governadas por $W_{aa}$, semelhante à $W_{ax}$. Também semalhante á $W_{ax}$, $W_{ya}$ governa os output predictions.\n",
    "\n",
    "A mágica das RNNs é que as informações de cada palavra na frase são multiplicadas pelos mesmos pesos, $W_x$. A informação propagada do início ao fim é multiplicada por $W_h$. O primeiro bloco é repetido para cada palavra na frase, então, os únicos parâmetros que podem ser aprendidos são os $W_x$, $W_h$ e $W$, os pesos utilizados para fazer a previsão final. É por isso que elas são chamadas de recurrent neural networks, elas calculam valores que são transmitidos repetidamente para si mesmas até que uma previsão seja feita. A principal vantagem das RNNs é que elas propagam informações em frases e seus cálculos compartilham a maioria dos parâmetros.\n",
    "\n",
    "Os hidden states em cada time step $t$ são calculados com uma função de ativação $g$, com os argumentos iguais ao produto entre uma matriz de parâmetros $W_h$ e os hidden states anteriores $h^{<t - 1>}$, isso é concatenado com a variável de input $x^{<t>}$, mais o viés $b_h$:\n",
    "$$h^{<t>} = g(W_h [h^{<t - 1>}, x^{<t>}] + b_h)$$\n",
    "Equação completa, onde $x^{<t>}$ e $h^{<t - 1>}$ são multiplicados por parâmetros diferentes e os vetores resultantes são somados element a elemento:\n",
    "$$h^{<t>} = g(W_{hh} h^{<t - 1>} + W_{hx} x^{<t>} + b_h)$$\n",
    "* $W_h[h^{<t - 1>}, x^{<t>}]$ é o mesmo que multiplicas $W_{hh}$ por $h^{<t - 1>}$ e $W_{hx}$ por $x^{<t>}$. Portanto, podemos concatenar.\n",
    "* $W_h$ denota a concatenação horizontal das matrizes de peso $W_{hh}$ e $W_{hx}$.\n",
    "    * A junção sobre o limite vertical é chaamda de `horizontal concatenation` ou `horizontal stack`, ou seja, $W_h = | W_{hh} | W_{hx} |$.\n",
    "\n",
    "Depois de calcularmos o hidden state no time step $t$, é possível obtermos a previsão $\\hat{y}^{<t>}$ usando a função de ativação $g$, com argumentos iguais ao produto entre o hidden state e alguns parâmetros $W$, mais o termo do viés $b_y$:\n",
    "$$\\hat{y}^{<t>} = g(W_{yh} h^{<t>} + b_y)$$\n",
    "\n",
    "Essas 2 equações juntas representam toda a matemática por trás de um RNN simples. A primeira cell da RNN recebe como input o hidden state anterior $h^{<t_0>}$ e a variável atual $x^{<t_1>}$, que pode ser a primeira palavra em uma frase. Para obtermos o hidden state atual $h^{<t_1>}$, primeiro precisamos obter os produtos de $x^{<t_1>}$ e $h^{<t_0>}$ com os respectivos parâmetros e, em seguida, somamos os vetores element-wise. Em seguida, passamos o vetor resultante em uma função de ativação.\n",
    "$$h^{<t>} = g(W_{hh} h^{<t - 1>} + W_{hx} x^{<t>} + b_h)$$\n",
    "Com o valor resultante, podemos calcular o $\\hat{y}^<t>$ multiplicando o hidden state atual, com um set de parâmetros $W_{yh}$ e passando por outra função de ativação.\n",
    "$$\\hat{y}^{<t>} = g(W_{yh} h^{<t>} + b_y)$$\n",
    "As hidden states $h^{<t>}$ são as variávels que fazem com que as RNNs propaguem informações ao longo do tempo ou, em outras palavras, por meio de posições diferentes na frase. Em cada time step as recurrent units têm 2 entradas.\n",
    "\n",
    "Podemos pensar em RNNs como ferramentas versáteis que podem ser moldadas de acordo com a tarefa. Portanto, de acordo com a natureza dos inputs e outputs, existem muitos tipos diferentes de arquiteturas de RNNs:\n",
    "\n",
    "* `One to One`: toma como input um set de low features ou features não correlacionadas $X$ e retorna um único output $y$. Digamos que temos uma lista de pontuações do nosso time favorito. Como inputs, podemos ter uma RNN que preve a posição de nossa equipe na tabela de classificação. No entanto, essa RNN não é muito diferente de uma rede neural convencional. Ela tem apenas hidden states $h^{<t_0>}$ adicionais. Portanto, para esse tipo de tarefa, as RNNs não são muito úteis.\n",
    "\n",
    "* `One to Many`: se queremos uma rede neural que pegue uma imagem arbitrária e gere uma caption descrevendo o conteúdo dessa imagem (caption generation task), podemos criar uma RNN. One to Many, porque nossa RNN pega uma única imagem e gera várias palavras para descrevê-la.\n",
    "\n",
    "* `Many to One`: se tivermos uma frase, a nossa RNN pegaria cada palavra da frase como input em diferentes steps, propagaria as informações do início ao fim e geraria um único output, o sentimento, por exemplo.\n",
    "\n",
    "* `Many to Many`: envolvem vários inputs e vários outputs. Por exemplo, em machine translation, temos uma frase em um idioma e desejamos obter seu equivalente em outro idioma, usamos um `encoder` e um `decoder` para traduzir de um idioma para outro. Podemos usar um sistema de machine translation que tenha RNNs para ambos o encoder e decoder, porque elas propagam informações do início ao fim e é isso que as torna capazes de capturar o significado geral das frases. O modelo tradicional `seq2seq` foi introduzido pelo Google em 2014. Basicamente, ele funciona recebendo uma sequência de itens, como palavras, e seu output é outra sequência. A maneira como isso é feito, é mapeando sequências de comprimento variável (variable-length sequences) para uma memória de comprimento fixo (fixed-length memory), que em machine translation, encodes o signifcado geral das frases. Por exemplo, podemos ter um texto de tamanho variável e codificá-lo em um vetor de dimensão fixa, como 300. Essa feature é o que tornou esse modelo uma potência para machine translation. Além disso, os inputs e outputs não precisam ter comprimentos correspondentes, o que é uma feature desejável ao traduzir textos. No modelo seq2seq, LSTMs e GRUs são normalmente usados para evitar esses problemas. Em um modelo seq2seq temos um encoder e um decoder:\n",
    "    * `Encoder`: recebe tokens como input e retorna seus hidden states finais $h_T$ como output.\n",
    "    * `Decoder`: recebe o output do encoder, os hidden states finais, que são usados pelo decoder como initial hidden states para gerar a frase traduzida no idioma de destino.\n",
    "\n",
    "Vanilla (simples) RNNs são limitadas no sentido de que, para longas sequências de palavras, as informações tendem a desaparecer, ou seja, o problema dos vanishing/exploding gradients. Portanto, modelos mais complexos foram criados para lidarmos com sequências longas e reduzir exponencialmente esse problema, esses modelos são a `GRU` e a `LSTM`. Deep RNNs são úteis porque permitem capturar dependências que, de outra forma, não poderíamos ter capturado usando shallow (rasas) RNNs. Ambas arquiteturas são derivadas da Vanilla (simples) RNN.\n",
    "* `Vanishing gradients`: quando calculamos o backprop, os gradients podem se tornar muito pequenos e, como resultado, o modelo não aprenderá nada.\n",
    "* `Exploding gradients`: se as derivadas parciais forem maiores que 1, a contribuição para o gradient vai para o infinito, o que causa problemas de convergência durante o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7900966-abe1-49c1-afd5-c21585c0f731",
   "metadata": {},
   "source": [
    "<a name=\"4.1\"></a>\n",
    "### Embedding\n",
    "**[EN-US]**\n",
    "\n",
    "Word embeddings is the method that encodes the meaning of the word into a vector space. When we encode and plot a word in 2D, similar words tend to be found close to each other. In practice, we will find embeddings with hundreds of dimensions, and we can think of each dimension as a number that tells us something about the word. Word embeddings have been one of the most important ideas in NLP. What we do to learn word embeddings is have a vocabulary of 10,000 words, for example, and we will learn a vector $e_1$, up to $e_{\\mathrm{VOCAB_SIZE}}$, which just learns a fixed encoding, learns a fixed embedding for each of the words $e$ in our vocabulary $V$. We can allow our algorithms to generalize much better.\n",
    "\n",
    "Encoding the meaning of words is also the first step to encoding the meaning of entire sentences, which is the basis for NLP use cases like question answering and neural machine translation, for example. Word embeddings represent words in a vector form that, at the same time:\n",
    "* It has a relatively low dimension, making it practical for calculations.\n",
    "* Allows us to encode the meaning of the word. It carries the meaning of words, making it possible to determine how semantically similar the words are.\n",
    "    * In general vocabularies, generally the vector for 'forest' will be similar to the vector for 'tree', which is very different from the vector for 'ticket'.\n",
    "$$\\text{forest } \\approx \\text{ tree }\\ \\ \\text{ forest} \\neq \\text{ ticket}$$\n",
    "* Allows you to make analogies, such as discovering the missing word in 'Paris is to France as Rome is to ?'\n",
    "$$\\text{Paris:France :: Rome:?}$$\n",
    "\n",
    "There are many types of possible methods for learning word embeddings, we create machine learning models to learn word embeddings. The model performs a `learning task`, and the main by-products of this task are word embeddings. For example, the task could be to learn to predict a word based on surrounding words in any sentence in the corpus, as in the case of `continuous bag-of-words (CBOW)`. The specificity of the task is what will ultimately define the meaning of individual words.\n",
    "\n",
    "The task is `self-supervised`, it is both unsupervised in the sense that the input data and corpus are unlabeled, and supervised in the sense that the data itself provides the necessary context that would normally constitute labels. Therefore, the corpus is an independent dataset that contains training data and data that allows task supervision.\n",
    "* self-supervised learning: it is a mixture of unsupervised learning and supervised learning.\n",
    "\n",
    "Word embeddings can be tuned by various hyperparameters, as in any model. One of these hyperparameters is the dimension of the word embedding vectors. In practice, this size normally varies from a few hundred to a few thousand. Using higher dimensions captures more subtle meanings, but it is more computationally expensive, both in terms of training time and later, when using word embedding vectors, this ends up resulting in diminishing returns.\n",
    "\n",
    "To input the corpus into the machine learning model, the corpus content must first be transformed into a suitable mathematical representation of words in numbers (tokenization). The representation depends on the specifics of the model, but is generally based on simple representations, such as integer based word indices or one-hot vectors.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "Word embeddings é o método que codifica o significado da palavra em um espaço vetorial. Ao codificarmos e plotarmos uma palavra em 2D, palavras semelhantes tendem a ser encontradas próximas umas das outras, na prática, encontraremos embeddings com centenas de dimensões e, podemos pensar em cada dimensão como um número que nos diz algo sobre a palavra. Word embeddings tem sido uma das ideias mais importantes em NLP. O que fazemos para aprender word embeddings é ter um vocabulários de 10.000 palavras, por exemplo, e aprenderemos um vetor $e_1$, até $e_{\\mathrm{VOCAB_SIZE}}$, que apenas aprende um encoding fixo, aprende um embedding fixo para cada uma das palavras $e$ em nosso vocabulário $V$. Podemos permitir que nossos algoritmos se generalizem muito melhor.\n",
    "\n",
    "Codificar o significado das palavras também é o primeiro passo para codificar o significado de frases inteiras, que é a base para casos de uso de NLP como question aswering e neural machine translation, por exemplo. Word embeddings representa palavras em uma forma vetorial que, ao mesmo tempo:\n",
    "* Tem uma dimensão relativamente baixa, tornando-á pratica para cálculos.\n",
    "* Nos permite codificar o significado da palavra. Carrega o significado das palavras, possibilitando determinar o quão semanticamente similares as palavras são.\n",
    "    * Em vocabulários no geral, geralmente o vetor para 'forest' será similar ao vetor para 'tree', o que é muito diferente do vetor de 'ticket'.\n",
    "$$\\text{forest } \\approx \\text{ tree }\\ \\ \\text{ forest} \\neq \\text{ ticket}$$\n",
    "* Permite fazer analogias, como descobrir que a palavra que falta em 'Paris é para France como Roma está para ?'\n",
    "$$\\text{Paris:France :: Rome:?}$$\n",
    "\n",
    "Há muito tipos de método possíveis de aprender word embeddings, criamos modelos de machine learning para aprender as word embedding. O modelo executa uma `learning task`, e os principais subprodutos dessa tarefa são as word embeddings. Por exemplo, a task pode ser aprender a prever uma palavra com base nas palavras circundantes em qualquer frase do corpus, como no caso do `cotinuous bag-of-words (CBOW)`. A especificidade da tarefa é o que acabará por definir o significado das palavras individuais.\n",
    "\n",
    "A task é `self-supervised (autosupervisionada)`, é tanto não supervisionada no sentido de que os dados de entrada e o corpus não estão rotulados, quanto supervisionada no sentido de que os dados em si fornecem o contexto necessário que normalmente constituiria os rótulos. Portanto, o corpus é um dataset independente que contém os dados de treinamento e os dados que permitem a supervisão da tarefa.\n",
    "* self-supervised learning: é uma mistura de aprendizado não supervisionado e aprendizado supervisionado.\n",
    "\n",
    "Word embeddings podem ser ajustadas por vários hiperparâmetros, como em qualquer modelo. Um desses hiperparâmetros é a dimensão dos word embedding vectors. Na prática, essa dimensão normalmente varia de algumas centenas a poucos milhares. Usar dimensões mais altas, capturamos significados mais sutis, mas é mais caro computacionalmente, tanto no que diz respeito ao tempo de treinamento, quanto posteriormente, ao usar os word embedding vectors, isso acaba resultando em retornos decrescentes.\n",
    "\n",
    "Para inserir o corpus no modelo de machine learning, o conteúdo do corpus deve primeiro ser transformado em uma representação matemática adequada de palavras em números (tokenização). A representação depende das especificidades do modelo, mas geralmente é baseada nas representações simples, como inteiros (integer based words indices) ou one-hot vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30120afb-5418-40fc-8c41-6d7a464183df",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### LSTM Layer\n",
    "**[EN-US]**\n",
    "\n",
    "The LSTM (Long Short Term Memory) -- as well as the GRU (Gated Recurrent Unit) -- was created to reduce the problem of vanishing/exploding gradients in a simple RNN. The LSTM is the best solution to deal with the problem of vanishing gradients, more robust than a GRU unit. But they still suffer from vanishin/exploding gradients issues when processing very long sentences. So, transformers were created, which do not suffer from this problem.\n",
    "> I will talk about transformers in the fine tuning of the DistilBERT model in the notebook `05_transformers_finetuning.ipynb`.\n",
    "\n",
    "LSTMs are a special variety of simple RNNs, which are designed to deal with entire sequences of data, learning when to remember and forget, which is similar to what is done in GRU. An LSTM is essentially composed of:\n",
    "* A `cell state`, which we can consider as its memory.\n",
    "* A `hidden state (memory state)` where calculations are performed during training to decide what changes should be made.\n",
    "* An LSTM has `multiple gates` that transform the states in the network. They discard irrelevant information and add new important information used to produce the output.\n",
    "\n",
    "<img align='center' src='../figures/LSTM.png' style='width:800px;'>\n",
    "The cell state passes through these gates and tracks the inputs as they arrive, each playing a role in deciding how much information should be passed on and how much should be left behind. The series of gates allows gradients to flow, avoiding the risk of `vanishing or exploding gradients`.\n",
    "\n",
    "An LSTM unit stores information in the cell and hidden states, denoted by $c^{<t>}$ and $h^{<t>}$ respectively and, just like in Vanilla (simple) RNNs, we have the inputs $x^{<t>}$ and the outputs $\\hat{y}^{<t>}$. Information flows through 3 different gates, in their respective order in which information flows:\n",
    "1. `Forget gate`: first, the cell state passes through the forget gate. In this step, the previous inputs and hidden states are used to decide which cell state information is no longer important and discard it.\n",
    "   $$\\Gamma_f = \\sigma(W_f [h_{t - 1}; x_t] + b_f)$$\n",
    "2. `Input gate`: then, the input gate is used to decide which information from the inputs and previous hidden states is relevant and, therefore, is added to the cell state.\n",
    "   $$\\Gamma_i = \\sigma(W_i [h_{t - 1}; x_t] + b_i)$$\n",
    "3. `Output gate`: then, the output gate determines the cell state information that is stored in the hidden state and uses it to create an output at a given time step $t$.\n",
    "   $$\\Gamma_o = \\sigma(W_o [h_{t - 1}; x_t] + b_o)$$\n",
    "\n",
    "Gates allow gradients to flow without changes. Sigmoid activation functions with different trainable parameters are applied to the inputs and previous hidden states for the 3 gates. The use of sigmoid guarantees that the gate values are between 0 and 1. In practice, the values found in the vectors corresponding to each gate are very close to 0 or 1. With a value of 0, the gate is closed so that information does not reach, while a value of 1 allows information to flow freely.\n",
    "\n",
    "Another significant calculation done within an LSTM is `candidate cell state`. To achieve this, we need to transform the information from previous hidden states and current inputs. The `tanh` activation function, typically used in different implementations, reduces information from previous hidden states and current inputs to be between -1 and 1. This non-linear transformation has been used in the past because it improves training performance, however, we can use other activations and test their behavior. Candidate cell (carry) state for time step $t$:\n",
    "$$g = \\mathrm{tanh}(W_g [h_{t - 1}; x_t] + b_g)$$\n",
    "\n",
    "With the forget gate, input gate and candidate cell state, we can update the cell state. To obtain the new cell state, we add the information from the candidate cell state that passes through the input gate to the information from the cell state, which passes through the forget gate. Cell (Carry) state for time step $t$:\n",
    "$$c_t = \\Gamma_f . c_{t - 1} + \\Gamma_i . g$$\n",
    "\n",
    "We then calculate the new hidden state used to produce the output at a given time step $t$. To obtain the new hidden state, we pass the transformed information of the new cell state through the output port. In the new cell state, we first undergo tanh activation. However, the tanh function can be omitted. LSTM unit output for time step $t$:\n",
    "$$h_t = \\Gamma_{o_t} . \\text{tanh}(c_t)$$\n",
    "\n",
    "A limitation of this particular neural network architecture is that the prediction at a given time uses inputs or uses information from earlier inputs in the sequence, but not information later in the sequence. We will use a bidirectional LSTM to deal with this problem.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "A LSTM (Long Short Term Memory) -- assim como a GRU (Gated Recurrent Unit) -- foi criada para reduzir o problema dos vanishing/exploding gradients de uma RNN simples. A LSTM é a melhor solução para lidar com o problema dos vanishing gradients, mais robusta do que uma GRU unit. Mas ainda sofrem com problemas de vanishin/exploding gradients ao processar frases muito longas. Portanto, foram criados os transformers, que não sofre com esse problema.\n",
    "> Falarei sobre os transformers no fine-tuning do modelo DistilBERT no notebook `05_transformers_finetuning.ipynb`.\n",
    "\n",
    "As LSTMs são uma variedade especial das RNNs simples, que foram projetadas para lidar com sequências inteiras de dados, aprendendo quando lembrar e esquecer, o que é similar ao que é feito na GRU. Um LSTM é essencialmente composto por:\n",
    "* Uma `cell state`, que podemos considerar como a sua memória.\n",
    "* Um `hidden state (memory state)` onde os cálculos são realizados durante o treinamento para decidir quais mudanças devem ser feitas.\n",
    "* Um LSTM tem `multiple gates` que transformam os states na rede. Descartam informações irrelevantes e adicionam novas informações importantes usadas para produzir o output.\n",
    "\n",
    "<img align='center' src='../figures/LSTM.png' style='width:800px;'>\n",
    "A cell state passa por esses gates e rastreia os inputs à medida que chegam, cada um desempenha um papel na decisão de quanta informação deve ser repassada e quanta deve ser deixada para trás. A série de gates permite que os gradients fluam, evitando o risco de `vanishing ou exploding gradients`.\n",
    "\n",
    "Uma LSTM unit armazena informações na cell e no hidden states, denotadas por $c^{<t>}$ e $h^{<t>}$ respectivamente e, assim como nas Vanillas (simples) RNNs, temos os inputs $x^{<t>}$ e os outputs $\\hat{y}^{<t>}$. A informação flue por 3 diferentes gates, em suas respectivas ordens em que as informações fluem:\n",
    "1. `Forget gate`: primeiro, a cell state passa pela forget gate. Nessa etapa, os inputs e os hidden states anteriores são usados para decidir quais informações da cell state não são mais importantes e as descartam.\n",
    "   $$\\Gamma_f = \\sigma(W_f [h_{t - 1}; x_t] + b_f)$$\n",
    "2. `Input gate`: em seguida, a input gate é usada para decidir quais informações dos inputs e dos hidden states anteriores são relevantes e, portanto, são adicionadas ao cell state.\n",
    "   $$\\Gamma_i = \\sigma(W_i [h_{t - 1}; x_t] + b_i)$$\n",
    "3. `Output gate`: em seguida, a output gate determina as informações da cell state que são armazenadas no hidden state e usa para criar um output em determinado time step $t$.\n",
    "   $$\\Gamma_o = \\sigma(W_o [h_{t - 1}; x_t] + b_o)$$\n",
    "\n",
    "As gates permitem que os gradients fluam sem alterações. As funções de ativação sigmoid com diferentes parâmetros treináveis são aplicadas aos inputs e aos hidden states anteriores para as 3 gates. O uso da sigmoid garante que os valores das gates estejam entre 0 e 1. Na prática, os valores encontrados nos vetores correspondentes a cada gate são muito próximos de 0 ou 1. Com um valor de 0, o gate é fechado para que as informações não cheguem, enquanto o valor de 1 permite que as informações fluam livremente.\n",
    "\n",
    "Outro cálculo significativo feito dentro de um LSTM é o `candidate cell state`. Para conseguir isso, precisamos transformar as informações dos hidden states anteriores e dos inputs atuais. A função de ativação `tanh`, é normalmente usada em diferentes implementações, ela reduz as informações dos hidden states anteriores e dos inputs atuais para ficarem entre -1 e 1. Essa transformação não linear foi usada no passado porque melhora o desempenho do treinamento, no entanto, podemos usar outras ativações e testar o comportamento delas. Candidate cell (carry) state para o time step $t$:\n",
    "$$g = \\mathrm{tanh}(W_g [h_{t - 1}; x_t] + b_g)$$\n",
    "\n",
    "Com o forget gate, input gate e a candidate cell state, podemos atualizar a cell state. Para obtermos a nova cell state, adicionamos as informações do candidate cell state que passa pela input gate às informações do cell state, que passa pela forget gate. Cell (Carry) state para o time step $t$:\n",
    "$$c_t = \\Gamma_f . c_{t - 1} + \\Gamma_i . g$$\n",
    "\n",
    "Em seguida, calculamos o novo hidden state usado para produzir o output em um determinado time step $t$. Para obtermos o novo hidden state, passamos as informações transformadas do novo cell state pela output gate. No novo cell state, passamos primeiro por uma ativação tanh. No entanto, a função tanh pode ser omitida. Output da LSTM unit para o time step $t$:\n",
    "$$h_t = \\Gamma_{o_t} . \\text{tanh}(c_t)$$\n",
    "\n",
    "Uma limitação dessa arquitetura de rede neural específica, é que a previsão em um determinado momento, usa inputs ou usa informações dos inputs anteriores na sequência, mas não informações posteriores na sequência. Usaremos uma LSTM bidirecional para tratar esse problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bd579-0088-47d2-9694-65ffd8f2fb9c",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## Bidirectional LSTM Model Train (Treinamento do Modelo LSTM Bidirecional)\n",
    "**[EN-US]**\n",
    "\n",
    "Bidirectional RNNs, at a given time, allow us to obtain information from the beginning and end of the sequence, allowing us to make predictions anywhere in the sequence. BRNN (Bidirectional RNN) corrects the problem of unidirectional RNN, because it takes into account information from the entire sequence. These hidden layers will have forward recurrent components (layers) like a unidirectional RNN, but they will also have backward recurrent components (layers), which connect to each other, going backwards in time. This neural network defines an `Acyclic graph`.\n",
    "\n",
    "In other words, they are very important, because knowing what comes next in the sequence can give you more context about the sequence itself, it propagates information about the future and the past over time. They work in the same way as unidirectional RNNs, they take a sequence $x$ of input and make predictions $\\hat{y}$. In unidirectional RNNs, information flows from the beginning to the end of the sequence. However, we could have another architecture where information flows from end to beginning, from future to present. When information flows in both directions, this is a `Bidirectional RNN`, this is an acyclic graph, that is, information flows independently in 2 directions, from the past and from the future independently.\n",
    "\n",
    "When calculating activations from right to left, it is not a back prop, it is a forward prop, because we compute the activations of the neural network. Where the forward prop has part of the computation going from left to right, and part of the computation going from right to left. Left-to-right calculations are completely independent of right-to-left calculations. To get $\\hat{y}$ predictions in a bidirectional RNN, we need to start propagating information from both directions. After calculating the 2 hidden states for a time step, we can obtain the prediction $\\hat{y}$ for that time step, using the hidden states from both directions and combining them to form a hidden state, proceeding as a Unidirectional RNN would do. Using the formula:\n",
    "$$\\hat{y}^{<t>} = g(W_y [\\vec{h}^{<t>}, \\leftarrow{h}^{<t>}] + b_y)$$\n",
    "This formula is the same as that used for a unidirectional or Vanilla RNN, but adding the 2 hidden states. After we calculate all the hidden states in both directions, we can obtain all the remaining predictions.\n",
    "> For a sentiment classification task, we only calculate the last output $\\hat{y}$, and not at each time step $t$.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "RNNs bidirecionais, em um determinado momento, nos permite obter informações do início e do final da sequência, nos permitindo fazer previsões em qualquer lugar da sequência. A BRNN (Bidirectional RNN) corrige o problema da RNN unidirecional, porque leva em consideraçõa informações de toda a sequência. Essas hidden layers terão componentes recorrentes diretos (`forward recurrent components (layers)`) como uma RNN unidirecional, mas também terão componentes recorrentes inversos (`backward recurrent componenets (layers)`), que se conectam umas às outras, retrocedendo no tempo. Essa rede neural define um `Acyclic graph`.\n",
    "\n",
    "Ou seja, são muito importantes, porque saber o que vem a seguir na sequence pode lhe dar mais contexto sobre a própria sequência, ela propaga informações do futuro e do passado ao longo do tempo. Trabalham da mesma forma que as RNNs unidirecionais, elas pegam uma sequência $x$ de input e fazem as previsões $\\hat{y}$. Nas RNNs unidirecionais, as informações fluem do início ao fim da sequência. No entanto, poderíamos ter outra arquitetura em que as informações fluíssem do final ao início, do futuro ao presente. Quando as informações fluem em ambas as direções, isso é um `RNN Bidirecional`, isso é um gráfico acíclico, ou seja, as informações fluem de forma independente nas 2 direções, do passado e do futuro independentemente.\n",
    "\n",
    "No cálculo das ativações da direita para a esquerda não é um back prop, é um forward prop, porque computamos as ativações da rede neural. Onde o forward prop tem parte da computação indo da esquerda para a direita, e parte da computação indo da direita para a esquerda. Os cálculos da esquerda para a direta são completamente independentes dos cálculos da direita para a esquerda. Para obter as previsões $\\hat{y}$ em um RNN bidirecional, precisamos começar a propagar informações de ambas as direções. Depois de calcularmos os 2 hidden states para um time step, podemos obter a previsão $\\hat{y}$ para esse time step, usando os hidden states de ambas as direções e os combinando para formar um hidden state, procedendo como faria uma Unidirectional RNN. Usando a fórmula:\n",
    "$$\\hat{y}^{<t>} = g(W_y [\\vec{h}^{<t>}, \\leftarrow{h}^{<t>}] + b_y)$$\n",
    "Essa fórmula é a mesma usada para uma RNN unidirecional ou Vanilla, mas adicionando os 2 hidden states. Depois de calcularmos todos os hidden states em ambas as direções, podemos obter todas as previsões restantes.\n",
    "> Para uma tarefa de classificação de sentimentos, calculamos apenas o último output $\\hat{y}$, e não em cada time step $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2d3f6-2688-4baf-ab51-3387c2a6f6cd",
   "metadata": {},
   "source": [
    "<a name=\"5.1\"></a>\n",
    "### Model Architecture (Arquitetura do Modelo)\n",
    "**[EN-US]**\n",
    "\n",
    "The RNN architecture used in the system is composed of the layers:\n",
    "* `Input()`: we specify the shape that will be our input, discarding the batch size.\n",
    "\n",
    "* `Embedding()`: the embedding return will be a 2D matrix with the sentence length (MAX_LEN) and the embedding dimension (EMBEDDING_DIM). Its return will be the input for the first bidirectional LSTM layer.\n",
    "\n",
    "* `Dropout()`: dropout for network regularization.\n",
    "\n",
    "* `BatchNormalization()`: applies batch normalization.\n",
    "\n",
    "* `Bidirectional(LSTM)`: Bidirectional LSTM layer. It will make the cell state in this layer go in both directions.\n",
    "    * `return_sequences`: we need to set it to True if the output of the current RNN layer is the input of the next RNN layer. This ensures that the outputs of the RNN correspond to the desired inputs of the next RNN layer. If we set it to True and the next layer is an FC (Dense), for example, we must apply another layer before the FC to transform this input, applying the average (GlobalAveragePooling1D) of the last axis, for example, or just (Flatten). If the next layer is not an RNN, we can set it to False.\n",
    "\n",
    "* `Dropout()`: dropout for network regularization.\n",
    "\n",
    "* `BatchNormalization()`: applies batch normalization.\n",
    "\n",
    "* `Dense()`: Fully Connected output layer with sigmoid activation.\n",
    "\n",
    "Optimizer, loss function and performance metrics:\n",
    "* `Optimizer`: Adam.\n",
    "\n",
    "* `Loss function`: Binary cross entropy.\n",
    "\n",
    "* `Evaluation metric`: F1 Score.\n",
    "\n",
    "Defining the best hyperparameters and the model, and plotting your information.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "A arquitetura da RNN utilizada no sistema é composta pelas layers:\n",
    "* `Input()`: especificamos o shape que será nosso input, descartando o tamanho do batch.\n",
    "\n",
    "* `Embedding()`: o retorno do embedding será uma matriz 2D com o comprimento da frase (MAX_LEN) e a dimensão do embedding (EMBEDDING_DIM). O seu retorno será o input para a primeira LSTM layer bidirecional.\n",
    "\n",
    "* `Dropout()`: dropout para regularização da rede.\n",
    "\n",
    "* `BatchNormalization()`: aplica a batch normalization.\n",
    "\n",
    "* `Bidirectional(LSTM)`: Layer LSTM bidirecional. Fará com que o cell state nessa layer vá nas as 2 direções.\n",
    "    * `return_sequences`: precisamos definir como True caso o output da layer RNN atual for o input da próxima layer RNN. Isso garante que os outputs da RNN correspondam aos intputs desejados da próxima layer RNN. Caso definimos como True e a próxima layer for uma FC (Densa), por exemplo, devemos aplicar outra layer antes da FC para transformamos esse input, aplicando a média (GlobalAveragePooling1D) do último eixo, por exemplo, ou apenas a (Flatten). Caso a próxima layer não for uma RNN, podemos definir como False.\n",
    "\n",
    "* `Dropout()`: dropout para regularização da rede.\n",
    "\n",
    "* `BatchNormalization()`: aplica a batch normalization.\n",
    "\n",
    "* `Dense()`: Fully Connected output layer com ativação sigmoid.\n",
    "\n",
    "Otimizador, loss function e métrica de desempenho:\n",
    "* `Otimizador`: Adam.\n",
    "\n",
    "* `Loss function`: Binary cross entropy.\n",
    "\n",
    "* `Métrica de avaliação`: F1 Score.\n",
    "\n",
    "Definindo os melhores hiperparâmetros e o modelo, e plotando as suas informações. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2340eda6-c40d-420a-ab82-b3e495f900a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_bidirectional_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_layer (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m16,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_bidirectional_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m304\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,389</span> (64.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,389\u001b[0m (64.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,349</span> (63.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,349\u001b[0m (63.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> (160.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m40\u001b[0m (160.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "# Melhores hiperparâmetros\n",
    "#lr = opt.x\n",
    "\n",
    "# Setting the model\n",
    "# Definindo o modelo\n",
    "model = create_and_compile_model(\n",
    "    MAX_LEN,\n",
    "    VOCAB_SIZE,\n",
    "    lr=LR,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    dropout_rate=DROPOUT_RATE\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a1922-970b-4c00-9112-957bae7f1e02",
   "metadata": {},
   "source": [
    "**[EN-US]**\n",
    "\n",
    "Setting the callbacks that will be used in training and training the model. The callbacks are:\n",
    "* `ModelCheckpoint`: saves model checkpoints at regular intervals during training, by default at the end of each epoch. If we use a validation set during training, we can set `save_best_only=True` and it will only save our model when the performance on the validation set so far is the best.\n",
    "    * This way, we don't need to worry too much about training and overfitting in the training set: we just restore the last model saved after training and this will be the best model in the validation set.\n",
    "* `EarlyStopping`: one of the ways to implement early stopping, that is, we stop training when the model does not calculate any progress in the validation defined by some epochs, defined by the `patience` argument and, optionally, will revert to the best model, defined by the `restore_best_weights` argument.\n",
    "* `ReduceLROnPlateau`: one of the ways to implement `performance scheduling`, it will multiply the learning rate by `factor` whenever the best `monitor` does not improve for `patience` consecutive epochs.\n",
    "    * `Performance scheduling`: calculates the validation error every $n$ steps, exactly as in early stopping, and reduces the learning rate by a factor of $\\lambda$ when the error stops decreasing.\n",
    "\n",
    "**[PT-BR]**\n",
    "\n",
    "Definindo os callbacks que serão utilizados no treinamento e treinando o modelo. Os callbacks são:\n",
    "* `ModelCheckpoint`: salva os checkpoints do modelo em intervalos regulares durante o treinamento, por padrão no fim de cada epoch. Se utilizarmos um validation set durante o treinamento, podemos definir `save_best_only=True` e ele apenas salvará nosso modelo quando o desempenho no validation set até então for o melhor.\n",
    "    * Desse modo, não precisamos nos preocupar muito com o treinamento e overfitting no training set: basta restaurarmos o último modelo salvo após o treinamento e este será o melhor modelo no validation set.\n",
    "* `EarlyStopping`: uma das formas de implementarmos a early stopping, ou seja, interrompemos o treinamento quando o modelo não calcular nenhum progresso na validação definida por algumas epochs, definido pelo argumento `patience` e, opcionalmente, reverterá para o melhor modelo, definido pelo argumento `restore_best_weights`.\n",
    "* `ReduceLROnPlateau`: uma das formas de implementarmos o `performance scheduling`, ela multiplicará a learning rate por `factor` sempre que a melhor `monitor` não melhorar por `patience` epochs consecutivas.\n",
    "    * `Performance scheduling`: calcula o erro de validação a cada $n$ steps, exatamente como na early stopping, e reduz a learning rate por um fator de $\\lambda$ quando o erro para de diminuir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0cbef6e-3416-4c54-98de-435bc05f62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "303/303 - 14s - 46ms/step - f1_score: 0.7241 - loss: 0.6998 - val_f1_score: 0.7709 - val_loss: 0.6538 - learning_rate: 0.0050\n",
      "Epoch 2/10\n",
      "303/303 - 9s - 30ms/step - f1_score: 0.7659 - loss: 0.6500 - val_f1_score: 0.7719 - val_loss: 0.6407 - learning_rate: 0.0050\n",
      "Epoch 3/10\n",
      "303/303 - 9s - 31ms/step - f1_score: 0.7661 - loss: 0.6413 - val_f1_score: 0.7683 - val_loss: 0.6330 - learning_rate: 0.0050\n",
      "Epoch 4/10\n",
      "303/303 - 9s - 31ms/step - f1_score: 0.7684 - loss: 0.6334 - val_f1_score: 0.7677 - val_loss: 0.6299 - learning_rate: 0.0050\n",
      "Epoch 5/10\n",
      "303/303 - 9s - 30ms/step - f1_score: 0.7721 - loss: 0.6195 - val_f1_score: 0.7688 - val_loss: 0.6224 - learning_rate: 0.0050\n",
      "Epoch 6/10\n",
      "303/303 - 9s - 29ms/step - f1_score: 0.7678 - loss: 0.6133 - val_f1_score: 0.7611 - val_loss: 0.6180 - learning_rate: 0.0050\n",
      "Epoch 7/10\n",
      "303/303 - 9s - 29ms/step - f1_score: 0.7716 - loss: 0.6093 - val_f1_score: 0.7704 - val_loss: 0.6143 - learning_rate: 0.0050\n",
      "Epoch 8/10\n",
      "303/303 - 9s - 30ms/step - f1_score: 0.7765 - loss: 0.6042 - val_f1_score: 0.7644 - val_loss: 0.6144 - learning_rate: 0.0050\n",
      "Epoch 9/10\n",
      "303/303 - 9s - 31ms/step - f1_score: 0.7769 - loss: 0.5963 - val_f1_score: 0.7672 - val_loss: 0.6081 - learning_rate: 0.0050\n",
      "Epoch 10/10\n",
      "303/303 - 9s - 29ms/step - f1_score: 0.7788 - loss: 0.5950 - val_f1_score: 0.7736 - val_loss: 0.6096 - learning_rate: 0.0050\n"
     ]
    }
   ],
   "source": [
    "# Setting the callbacks\n",
    "# Definindo os callbacks\n",
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=.5, patience=2)\n",
    "checkpoint_cb = ModelCheckpoint('../models/lstm_model.keras', save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training the model\n",
    "# Treinando o modelo\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_data=val_set,\n",
    "    callbacks=[reduce_lr_cb, checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6782a-28bf-4c4b-94df-296add27123a",
   "metadata": {},
   "source": [
    "Plotting loss and evaluation metrics during model training (Plotando a loss e a métrica de avaliação durante o treinamento do modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb4e336a-fb3c-4484-8a03-f84e11195162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, 'f1_score', name='model_history')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce07db2-9dbd-49f5-863b-d3be04dca521",
   "metadata": {},
   "source": [
    "Evaluating the model on training and validation data (Avaliando o modelo nos dados de treino e de validação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38ef6285-b927-44fa-9bfc-28d2d4f61019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set evaluate: 0.8146\n",
      "Validation set evaluate: 0.7672\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set evaluate: {model.evaluate(train_set, verbose=0)[1]:.4f}')\n",
    "print(f'Validation set evaluate: {model.evaluate(val_set, verbose=0)[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d39e586-c788-4ecc-96cf-368955655b59",
   "metadata": {},
   "source": [
    "Evaluating the final model on the test set (Avaliando o modelo final no test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3901b558-8d92-4299-bbf4-edf621de3ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluate: 0.7641\n"
     ]
    }
   ],
   "source": [
    "print(f'Test set evaluate: {model.evaluate(test_set, verbose=0)[1]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
